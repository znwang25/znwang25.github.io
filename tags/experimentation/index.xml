<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Experimentation on Zenan Wang&#39;s Site</title>
    <link>https://zenan-wang.com/tags/experimentation/</link>
    <description>Recent content in Experimentation on Zenan Wang&#39;s Site</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 10 Jun 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://zenan-wang.com/tags/experimentation/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>How to use CVR as an objective in multi-armed bandit experiments</title>
      <link>https://zenan-wang.com/blog/banditcvr/</link>
      <pubDate>Fri, 10 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>https://zenan-wang.com/blog/banditcvr/</guid>
      <description>How to use CVR as an objective in multi-armed bandit experiments  This article draws on our published paper  in the Web Conference 2022 
 Photo by Mitchel Boot  on Unsplash 
Intro Multi-armed bandit (MAB) has become an increasingly important tool for experimentation and has been widely adopted by the industry giants such as Google, Meta, Netflix, LinkedIn, etc. to conduct efficient experiments. However, widely-used MAB test designs require the objective of interest to provide instantaneous feedback in order to update the assignment probability to each variant.</description>
    </item>
    
  </channel>
</rss>
